{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9c20fb11-9c90-45a9-a4ea-610c602c496a"
    }
   },
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Prerequisite Data ##\n",
    "In order for the code cells to run correctly three pickle files need to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The pickle files are read in by the notebook but\n",
    "# aren't expected to be sent in back to udacity for evaluation.\n",
    "# Thus we get the files and provide them in the appropriate paths\n",
    "# for consumption by the subsequent code cells. Once done we delete\n",
    "# them from our repo and then submit for evaluation\n",
    "# wget https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip\n",
    "# unzip traffic-signs-data.zip\n",
    "# eventually we will also delete the three pickled files extracted by the unzip operation\n",
    "# rm traffic-signs-data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup relevant module imports ###\n",
    "For some reason, on the standard udacity-carnd ami, cv2 and tensorflow installs end up on a different path than what the sys.path property is expecting. Hence i had to augment that property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import sklearn\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.5/dist-packages')\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ec4c5a02-ee7b-4d16-a7dd-8680818bbe1f"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Step 1: Dataset Exploration\n",
    "\n",
    "Visualize the German Traffic Signs Dataset. This is open ended, some suggestions include: plotting traffic signs images, plotting the count of each sign, etc. Be creative!\n",
    "\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- features -> the images pixel values, (width, height, channels)\n",
    "- labels -> the label of the traffic sign\n",
    "- sizes -> the original width and height of the image, (width, height)\n",
    "- coords -> coordinates of a bounding box around the sign in the image, (x1, y1, x2, y2). Based the original image (not the resized version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1cfe204d-d46a-47cc-ba40-ca84249c83da"
    }
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "training_file = 'train.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "original_y_train = y_train\n",
    "setOfLabels = set(y_train)\n",
    "X_train_mean = np.mean(X_train)\n",
    "\n",
    "# Free up memory\n",
    "del train  \n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5f7aee15-5c4c-4684-9ad8-0f22df3098b3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "# Turn labels into numbers and apply One-Hot Encoding\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "# Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "62d87a6e-72cf-4bb3-adde-b8838fa8b3cc"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAF9CAYAAACUBRs8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XlcVFX/B/DPGZB12FXUFFA0wS0BU8Eld9BcS8slFZ/s\n0VRMyy0t9we3MpdHbbHU3MvHrXJLLEPMJUhScSXXRLSfgqGCAt/fH7M0AzMICmL1eb9e82Lm3LPd\nM+Pc7z333FGJCIiIiIg0pd0BIiIiejIwKCAiIiIADAqIiIhIj0EBERERAWBQQERERHoMCoiIiAgA\ngwIiIiLSY1BAREREABgUEBERkR6DAvpHUUrlmjz6lUL735u0/9njbp+IqCAMCqhYKaWey3PgNTyy\nlVJpSqkjSqmFSqkapdhN0T9Ks+1iaV8ptdxkjPcUR51E9M9lW9odoL+tvAc9BcAFQD39Y4BS6jkR\niX/M/Rpl8vzwY27bQKH4ghLJ85eI6KExKKCSth7AT9B91hoCeAG6A5gjgAn614+NiMx9nO0RFZZS\nqgwAJSL3Srsv9M/FywdUUpT+7w4RmSsis0WkO4Bj+m0KQIBZAaWeUUotUkodUEpdVkrdUUrdVUqd\nV0qtU0o1ydeIUjZKqRFKqf1KqZtKqftKqd+VUseUUiuUUi/nyV/gmgKlVAOl1GdKqTNKqdtKqT+U\nUqf0aVULvfNKdVNKHdTvw1Wl1FKlVLkHlBmllNqkb+//lFL39Pt0UCk1XinlZJK3v1IqF0B/QxKA\nFnn2r/nDjusD+umllHpPP8YZSqkspVSKvp8LlVIN8/ZT/8ixUJfF9yNvOaWUq1JqgVLqir7NPUqp\nZ/V5qyqlNiilbiilbimltiulaudpxzdPWy2VUm8opU7qx+OoUqqPPq+TUmqufqzuKqUSlFJdLPS9\nq1Lqc6VUov49ztJ/Xo7rx8HXQhmzNSVKqdpKqc1Kqd8BZAEYkqef1fOUV/q2DNtHF+W9I3ogEeGD\nj2J7AHgOQK7+kQOgnz5dA6AxgDR9ei6APXnKDjUpl/dhVp9JmeV52stbZn+e/Kb58tY10aScpfo6\nF3IMBlspnwxdUGTY9lmectcL2PdcAEcAOOnz9rewPW+55g87rgXsmz2Ak1baNKRFm+Tvb5rPQn0W\n34+85aC71JObp63bADoB+D8L/bgGwMukPt9C1Jejf+8OWtiWDaBlnr5/+YBxTQNQO0+Z70zyxAP4\nI0+5egB+MXk9M0/5FiZt3gPgXdr/5vn4ez14+YBKikB39rpcKbXcQnoOgNl5ymQB+BG6g9//AcgA\n4AagNXSXHgDgfaXUehHJUko5A+iDP6+nbwDws76ML3QBSqGutSulegCYbJL/NoB1AC4AqArdwacw\n9TwFYK7Jft4C8Cl0X+T/0tdlzSUAMQAuAripL18VwMsAnAHUBTAEwHvQHdRGA+gJoIG+vV8BLDGp\nL1n/t0jj+oBdbAngaX17mQCWArgCoAKA6tCNuSWPso5CAagP4CPo3pco6C5HOQDYAuA+gMUA7AC8\npm/HC8CryP8ZM9QXDGAbdJe2BgKoqN+2WF9+M4AkAMOhG3sF3Xh/Z1LPTQA7AZzQP78HwBtAN+g+\nfy4AZgHoaKF9ARCk7/vnAM5CN3OWCeC/AD7U5+2nlJogIoZZlh4m9ewQkVRLA0b0sBgUUEmztOBQ\nALwjIjvMMoosBbBUKVUXugOgF3TBw1boDl4KgCd0B8E4AGUA2OiLpwPoIyLZZo1ZmMK1Yiz+PJBn\nAAgSEcNBFUopR+gODg/yCnQHK+jr6yoi3+vr2Kjvt8WDo4gEK6VcAYQB8NG3dxJAAoDm+nLhAN4T\nkSQASfqxaqCv4pJYWDPxEONaEAeT53tF5A3TjUp3XbzsA+ooKgHwrojM1LdREUAvk23jROQD/ba6\n0M1ICYBnC6hvp4h01Jf5DbqAw3BXyNci8oJ+mwbAOH05s/pE5N9KKVt9ezUAuAL4DcAeAAOgG9dW\nSikbk4O6geHfwYsi8rXZBqUuA5gJwB26IKMTgM36vpiuwfnUyv4RPTQGBVSSBH8uNLQBUBu6L/My\nAGYopexEZJohs1IqGLqzplpW6jKsU6gMACKSppQ6rq/XDcB5pdRhAGcAHAUQIyIXHtRJ/QE/yKSd\nz00DAn1bdwHcLcQ+NzB5nmoICPR1/KiUOgfd2b9ZYKCUUtCdVQ6H7ow3L8P+Vy5EH8wUdVwf4DB0\nMw/2ACKUUsegm+4+Dd0sTYyIpBS1jwUwHDxXm6Sdz5PnS5PnydAdpAHAo4B611qoz9BW3voMzOrT\nr0GYB12QlZdhXO2hC5IsndEfyxsQAICI3FG637B4U5/0GnQzF89BFyQAwO8A8pUlelQMCqikGL5g\nd4jI58ZEpX6FbpoeAN5RSi0VkRSllAN0X3LeePA0s73J894A1kB3wKsIoDP+PMjlKqXmi8hbD6jP\nw6S/AHDuAfkL4q7/K9Bd184rFZYvIbwB3e2SD/oNA/sCtuXzCONqkYj8ppTqD2AhdAe7QP3DMOYZ\nSqnXRGR9IfpmKfix5orJ87yr8023mc4UWVpIbXifH6Y+ZXyiVBCAFUChLotYGleBbhbImv8CGAHd\nPrTTX5Z6yaTsSguzD0SPjHcf0ONm+tsAtvhzSrY5dNelDd4DUE5EbABoYeXLV0SOikhd6BZoRQL4\nD3TXig1naiOUUtaucxvczFN3oe8ysCBN/1cBKG9hu7eFNED3hW/o8xXopvXt9fv/HkwOSEX0UONa\nEBH5AkAlAE0BvA7dGooEfT1a6C5VGO6UyDUtqw9SDAr9A1YFHQBFJNfatgLcL2BbdgHbDHpA9/1p\nGL+eALT6ce2Iwr1ft61tEJHzAL7Rv9QA+Dd0axUMlheifqIiY1BAj1ujPK8NawIMU7CGL9M1InJD\n//zlPNuMlFLPAICIHBeRlSIyUX+t+KhJ/uCCOqS/NPAz/rxVsq9Syj9POw7qAbcU6v1k8txbKdXS\npI4wWLh0oGfYfwHwk4jEi0i2/iDayUoZwPzg5mRh+0ONqzVKKQ+llI+I5IjIjyLysYiMBtAGfx4g\nnQDU1BdJy1NFY309CsD4orb/BDG9ZJAuIl/qP0fAn+P6qBaaPB+NP4PMeBE5VkxtEJnh5QMqKYaD\nWHv9wdR0TYHpHQgH9flO5Sm3Wim1HrqD6CsmZfI6qF8oFgvdGfYt6Faq1zPJk/fAZMlMAF/on7sA\nOKKUMtx9UAW6s7/XoVucV5DV0F0esdf3d7NSaqm+//8y2Y+8B/lT+PPMuaNS6kMAV6E7I60J637T\n/1UAQpRS86C7i+GeiCzEw4+rNU8D+FG/diMRujHPBhBh0g/Bn2Meb9K2ArBJKbVLv0/1HqL9R1XQ\nrEhRZkxOmTx3V0ptA7AfQDMAbVEM+yUiu5VSJ6EbK8MlCAHA/zODSk5p3xPJx9/rAfPfKbD2MNyD\nPSFP2W0wv9/deD9/ntem97PftVDGtI0zAFxM8lusR7/tXegOcHnvuzfkL+zvFAyxUscl6A4mhtef\nmZRpAt217bxl0vHn/fC5AH7N09YzJn02LXfrUca1gH1rZJLf2nv7RZ4yn1tp/6sC3tf+ptvy1Dep\ngG3LTLbtMUn3zdNWcyuf2bzbLPYDunUolws5rj4m5b6z9P4/4LNkOt53ALiV9r9zPv6+D14+oJIg\nVh6Z0K303gAgXET+k6fcC9Ct5r4C3Qr3MwDehu4+cmsL8AZDdyBIhG5h333ofhDmF+hW8zcWkT8s\n9C1/p3V3QjSGbgHZr9AFHLehW4H+OXQ/PPTgnRdZDKA7dGfJmdD9KNEK6A6oV2A+JoYycQDaQXe2\nmQndmfbX0N2eeMxSGX25ROiuZyfo+2sp38OMqzWnoFsVv1H/PA26oOQGgH3Q3T3RK0+ZV6Fby3BZ\n3/4p6KbDuz6gfYv7/Ajbiq0+EbkJXSC3EbrA7Q50s17doHuvH7atvFZAN/tlKLdJRNILUY7ooSiR\nIq0xIiKix0gplQTdDxsJgAgR+baUu0R/Y1xTQET0hNEvoC0H3VoWw/8RcooBAZU0zhQQET1hlFLf\nQ3c7qUEugI6S51dAiYob1xQQET15DGsObkP32x5dGRDQ48CZAiIiIgLAmQIiIiLSY1BAREREABgU\nEBERkR6DAiIiIgLAoICIiIj0GBQQERERAAYFREREpMeggIiIiAAwKCAiIiI9BgVEREQEgEEBERER\n6TEoICIiIgAMCoiIiEiPQQEREREBYFBAREREegwKiIiICACDAiIiItJjUEBEREQAGBQQERGRHoMC\nIiIiAsCggIiIiPQYFBAREREABgVERESkx6CAiIiIADAoICIiIj0GBURERATgIYICpVQzpdRWpdRv\nSqlcpVRnC3mmKqWuKKXuKKW+VUpVL57uEhERUUl5mJkCZwBHAAwBIHk3KqXGAhgG4N8AGgK4DWCn\nUsruEfpJREREJUyJ5DuuF76wUrkAuorIVpO0KwDmiMgH+teuAFIB9BeRLx6xv0RERFRCinVNgVKq\nKoAKAGIMaSJyC8BBAKHF2RYREREVL9tirq8CdJcUUvOkp+q35aOU8gIQDuA8gMxi7g8REdHfmQMA\nPwA7ReT/HrWy4g4KHkY4gNWl3QkiIqK/sD4A1jxqJcUdFFwFoAB4w3y2wBvAz1bKnAeAVatWITAw\nsJi7Q9aMHDkSH3zwQWl34x+FY/74ccwfP47543XixAm88sorgP5Y+qiKNSgQkXNKqasAWgP4BTAu\nNGwEYJGVYpkAEBgYiODg4OLsDhXAzc2N4/2YccwfP47548cxLzXFcvm9yEGBUsoZQHXoZgQAoJpS\n6hkAN0TkEoB5AN5RSp2FLnKZBuAygC3F0WEiIiIqGQ8zU9AAwHfQLSgUAO/r01cA+JeIzFZKOQH4\nCIA7gFgA7UXkXjH0l4iIiEpIkYMCEdmLB9zKKCKTAUx+uC4RERFRaeD/ffAP1atXr9Luwj8Ox/zx\n45g/fhzzv7ZH+kXDYumAUsEA4uPj47k4hYiIqAgSEhIQEhICACEikvCo9XGmgIiIiAAwKCAiIiI9\nBgVEREQEgEEBERER6TEoICIiIgAMCoiIiEiPQQEREREBYFBAREREegwKiIiICACDAiIiItJjUEBE\nREQAGBQQERGRHoMCIiIiAsCggIiIiPQYFBAREREABgVERESkx6CAiIiIADAoICIiIj0GBURERASA\nQQERERHpMSggIiIiAAwKiIiISI9BAREREQFgUEBERER6DAqIiIgIAIMCIiIi0mNQQERERAAYFBAR\nEZEegwIiIiICwKCAiIiI9BgUEBEREQAGBURERKTHoICIiIgAMCggIiIiPQYFREREBIBBAREREekx\nKCAiIiIADAqIiIhIj0EBERERAWBQQERERHoMCoiIiAgAgwIiIiLSY1BAREREABgUEBERkR6DAiIi\nIgJQAkGBUkqjlJqmlPpVKXVHKXVWKfVOcbdDRERExcu2BOocB2AQgH4AkgA0ALBcKZUmIv8tgfaI\niIioGJREUBAKYIuI7NC/vqiU6g2gYQm0RURERMWkJNYU7AfQWilVAwCUUs8AaAJgWwm0RURERMWk\nJGYKZgJwBXBSKZUDXeAxQUTWlUBbREREVExKIih4GUBvAD2hW1NQH8B8pdQVEVlprdDIkSPh5uZm\nltarVy/06tWrBLpIRET017J27VqsXbvWLC09Pb1Y21AiUrwVKnURwAwRWWKSNgFAHxGpZSF/MID4\n+Ph4BAcHF2tfiIiI/s4SEhIQEhICACEikvCo9ZXEmgInADl50nJLqC0iIiIqJiVx+eArAO8opS4D\nOA4gGMBIAEtLoC0iIiIqJiURFAwDMA3AIgDlAVwBsESfRkRERE+oYg8KROQ2gDf1DyIiIvqL4HV+\nIiIiAsCggIiIiPQYFBAREREABgVERESkx6CAiIiIADAoICIiIj0GBURERASAQQERERHpMSggIiIi\nAAwKiIiISI9BAREREQFgUEBERER6DAqIiIgIAIMCIiIi0mNQQERERAAYFBAREZEegwIiIiICwKCA\niIiI9BgUEBEREQAGBURERKTHoICIiIgAMCggIiIiPQYFREREBIBBAREREekxKCAiIiIADAqIiIhI\nj0EBERERAWBQQERERHoMCoiIiAgAgwIiIiLSY1BAREREABgUEBERkR6DAiIiIgLAoICIiIj0GBQQ\nERERAAYFREREpMeggIiIiAAwKCAiIiI9BgVEREQEgEEBERER6TEoICIiIgAMCoiIiEiPQQGVmgsX\nLkCj0eCXX34p7a4YnTp1CqGhoXB0dERwcPBjabNq1apYsGBBofPv3bsXNjY2uHXrVgn26q9vwIAB\neOGFF0q7G0R/KQwK/sEiIyOh0Wgwe/Zss/QtW7ZAo3k8Hw2l1GNpp7AmTZoErVaLM2fOICYmxmKe\nli1b4s033yy2Nn/66Sf8+9//LnT+Jk2aICUlBa6ursXWB3r8PvzwQzzzzDNwc3ODm5sbwsLCsGPH\nDqv5Bw8eDI1GYxZAGgJrGxsbaDQas8f//vc/Y76EhAS0a9cOHh4eKFeuHAYNGoTbt2+b1R8TE4Mm\nTZrA1dUVlSpVwrhx45Cbm1v8O05PNAYF/2BKKTg6OmLWrFlIT0/Pt+1xEJFir/P+/fsPXTY5ORlN\nmzZF5cqV4eHh8Uj9yMnJKVQ+Ly8vODg4FLpeW1tblC9f/mG7RU+IKlWqYNasWUhISEB8fDxatWqF\nLl264MSJE/nybtq0CQcPHsRTTz1llu7j44OrV68iJSUFV69exdWrVzFlyhS4uLigffv2AICUlBS0\nbdsWTz/9NA4dOoQdO3bg+PHjiIyMNNaTmJiI559/Hh06dMCRI0ewfv16bN26FePGjSvRMaAnkIiU\n6gNAMACJj48XerwiIyOlc+fOUqtWLRkzZowxffPmzaLRaIyvJ0+eLPXr1zcrO2/ePPHz8zOrq2vX\nrhIdHS3e3t7i7u4u06ZNk+zsbBk9erR4enpK5cqVZdmyZcYy58+fF6WUrFu3TsLCwsTBwUHq1Kkj\ne/fuNWvr6NGj0r59e9FqteLt7S19+/aV33//3bi9RYsWMmzYMBkxYoSULVtWWrVqZXF/c3NzZcqU\nKVK5cmWxt7eX+vXry44dO4zblVKi0WiMf6dMmWJxzPLmu3Dhgnz//feilJLt27dLSEiI2Nvby969\neyU5OVm6dOki3t7eotVq5dlnn5Xdu3eb1enn5yfz588368fSpUulW7du4uTkJDVq1JCtW7catxva\nSk9PFxGR5cuXi7u7u+zcuVMCAwNFq9VKRESEXL161VgmOztboqKixN3dXcqVKyfjx4+X/v37S9eu\nXS2OlUFsbKw0a9ZMHB0dxcfHR4YPHy63b98WEZGTJ0+Kk5OTrF271ph//fr14ujoKCdOnBARkcOH\nD0vbtm2lbNmy4ubmJs8995wkJCSYtaGUko8++kg6duwoTk5OEhgYKD/++KOcPXtWWrRoIc7OzhIW\nFia//vqrsYzhM/nRRx9JlSpVxMnJSV566SXjmBjeq27duhlf5+bmSnR0tFStWlUcHR2lfv36smHD\nBuP2mzdvSu/evaVcuXLi6OgoTz/9tCxfvrzA8Slunp6e8tlnn5mlXb58WapUqSJJSUn5PiuWBAUF\nyWuvvWZ8/fHHH0uFChXM8hw9elSUUpKcnCwiIuPHj5eGDRua5fnqq6/EyclJMjIyHmWXqITFx8cL\nAAEQLMVwTOZMwT+cjY0NoqOjsXDhQly5csVqPkszB3nT9uzZg5SUFMTGxuKDDz7AxIkT0bFjR3h6\neuLQoUMYPHgwBg0alK+dMWPGYPTo0Thy5AhCQ0PRqVMn3Lx5EwCQnp6O1q1bIyQkBAkJCdi5cyeu\nXbuGl156yayOzz//HPb29ti/fz8+/PBDi/swb948fPDBB5g7dy6OHj2K8PBwdO7cGcnJyQCAq1ev\nolatWhg1ahRSUlIwatSofHXMnz8foaGheO2115CamoqUlBRUqVLFuP3tt9/GrFmzcOLECdSrVw8Z\nGRl4/vnn8d133+HIkSNo3749OnfujMuXL1sdawCYOnUqevbsiaNHj6JDhw7o06cP0tLSrI79nTt3\n8P7772P16tWIjY3FxYsXzfo/c+ZMrF27FitWrMC+fftw8+ZNbN68ucAZoeTkZLRv3x49evTAsWPH\nsH79esTFxSEqKgoAULNmTbz33nt4/fXXcfnyZVy+fBmvv/465syZg4CAAADAH3/8gcjISOzfvx8H\nDx7E008/jQ4dOuSbup4+fToiIyORmJiIwMBA9O7dG4MHD8aECRMQHx8PEcGwYcPMypw9exZffvkl\nvvnmG+zcuRM///wzhg4danV/oqOjsWrVKnz88cdISkrCyJEj0bdvX8TGxgIA3nnnHZw8eRI7d+7E\nyZMnsWTJEpQtW9ZqfTNmzICLi4vVh6ur6wPfZ4Pc3FysW7cOd+7cQWhoqDFdRNCvXz+MGTMGgYGB\nD6wnPj4eR44cwauvvmpMy8rKgp2dnVk+w8zUvn37jHnyzlY5ODggMzMT8fHxhdoH+psojsgi7wNA\nJQArAfwO4A6ARFiJYsCZglJjeiYVGhoqAwcOFBHLMwVBQUFmZefNmydVq1Y1q8v0tYhIQECAPPfc\nc8bXOTk5otVqZf369SLy50zBnDlzjHmys7OlSpUqxrTp06dLRESEWb2XLl0SpZScOXNGRHQzBSEh\nIQ/c36eeekpmzpxpltawYUMZNmyY8XX9+vUtzhCYatGihYwcOdIszXD2/tVXXz2wH3Xq1JFFixYZ\nX1uaKZg0aZLx9e3bt0UpJTt37jS2pdFozGYKNBqNnDt3zlhm8eLFUrFiRePrChUqyNy5c42vc3Jy\nxNfX1+xMOq+BAwfK4MGDzdJiY2PFxsZGsrKyjGmdOnWS5s2bS5s2baR9+/YF7ntOTo64urrKN998\nY3V/Dxw4IEops7P0devWiZOTk/H15MmTpUyZMpKSkmJM27Fjh9ja2kpqaqqImH++s7KyxNnZWQ4c\nOJBvH/v06SMiIp07d5ZXX321wP6bunnzpiQnJxf4yMnJKbCOo0ePilarFVtbW/Hw8JDt27ebbY+O\njjb7/D9opuD111+X2rVrm6UdP35c7OzsZM6cOXLv3j25ceOGdO/eXTQajfHfw65du8TW1lbWrl0r\nOTk5cvnyZWnevLloNBpZt25doceEHr/inimwLe4gQynlDiAOQAyAcH1gUAPAzeJui4rPrFmz0Lp1\na4tnx4VVu3Zts9fe3t6oW7eu8bVGo4GXlxeuXbtmlq9x48bG5zY2NmjQoIHxumpiYiL27NkDFxcX\nszJKKSQnJ6N69eoAgJCQkAL79scff+DKlSsICwszS2/SpEmx3f2glMrXj9u3b2PSpEnYtm0bUlJS\nkJ2djczMTFy8eLHAukzHzcnJCa6urvnGzZSTkxP8/PyMrytWrGjMf+vWLaSmpuLZZ581btdoNAgJ\nCSlwTUdiYiKOHj2KVatWGdMM+c+dO4eaNWsCAD799FM8/fTTsLGxwfHjx83quHbtGiZMmIC9e/fi\n2rVryMnJwd27d/Ptv+n+ent7AwDq1KljlpaZmYmMjAxotVoAuuvpFSpUMOYJDQ1FTk4OTp06lW/N\nxdmzZ3Hnzh20bdvWbJ/v379vvMvk9ddfx4svvoj4+Hi0a9cOXbt2NTtrz8vd3R3u7u5WtxdGQEAA\nEhMTkZ6ejg0bNqBfv3744YcfEBAQgPj4eCxYsAA///xzoerKzMzE2rVrMWnSJLP0WrVqYcWKFXjz\nzTfx9ttvw9bWFsOHD0f58uWNC4rbtm2LOXPm4PXXX0ffvn3h4OCAd999F7GxsY9t0TE9GYo9KAAw\nDsBFERloknahBNqhYtSsWTOEh4dj3LhxZguQAN0BJO/Bw9JivjJlypi9VkpZTCvKiuaMjAx07twZ\ns2fPzteHihUrGp87OzsXus6SlLcfb731FmJiYvD+++/D398fjo6OePHFF3Hv3r0C6ynquFnKX9AB\nvzAyMjIwaNAgvPHGG/nq8vHxMT4/cuQIbt++DRsbG6SkpBgP6gDQr18/3Lx5EwsXLoSPjw/s7e3R\nuHHjfPtv2n/DJQ1LaQ+7Gj4jIwMAsG3bNlSqVMlsm729PQAgIiICFy9exLZt2/Dtt9+iTZs2GDp0\naL67cwxmzJiB6Ohoq20qpZCUlITKlStbzWNra4tq1aoBAIKCgnDo0CHMnz8fS5Yswb59+3D9+nWz\ny1M5OTl48803MW/ePPz6669mdX355Ze4e/cu+vbtm6+dnj17omfPnrh+/brxM/r+++8b2waAESNG\nYMSIEbh69So8PDxw7tw5jBs3ziwP/f2VRFDQCcAOpdQXAJ4D8BuAxSKytATaomI0Y8YM1K9f33gG\naFCuXDlcvXrVLK2wZy+FceDAATRt2hSA7ksvPj4ew4cPBwAEBwdj48aN8PX1faQzFhcXF1SqVAlx\ncXFo1qyZMT0uLg6NGjUqUl12dnaFvrNg//79iIyMROfOnQHoDk7nz58vUnuPytXVFd7e3jh8+LBx\nnHNzc5GQkICgoCCr5YKDg5GUlISqVatazXPz5k0MGDAA77zzDlJSUtC7d2/8/PPPxgPt/v37sWTJ\nEoSHhwMALl26hN9///2BfS7M3S8XL17E1atXjbMFP/74I2xsbPJ9fgHd2bK9vT0uXLhgHANLvLy8\n0LdvX/Tt2xdNmzbFmDFjrAYFr7/+Ol5++eUC+5g3AHmQ3NxcZGVlAdAFVG3btjXb3q5dO/Tr1w8D\nBgzIV/azzz5D586d4eXlZbX+cuXKGfM6Ojrmqx+AcTzXrFkDHx+fx/Z7HfRkKImgoBqA1wG8D+A/\nABoCWKCUyhKRlSXQHhWTOnXqoE+fPvl+SKdFixYYNmwYZs+eje7du2P79u3YsWMH3NzciqXdRYsW\noXr16ggMDMTcuXORlpZm/NIbOnQoli5dip49e2LMmDHw9PTEmTNnsH79enz66adFunVy9OjRmDx5\nMqpVq4b69evjs88+Q2JiItasWVOk/vr5+eHgwYO4cOECtFotPD09AVi+vbJGjRrYuHEjOnbsCACY\nOHFisdxwdOSXAAAgAElEQVSGWdQ6oqKiEB0dDX9/fwQEBGDhwoVIS0srcPzGjh2L0NBQREVFYeDA\ngXB2dsbx48exe/duLFy4EAAwaNAg+Pr64p133kFmZiaCg4Px1ltv4b///S8A3f6vXLkSISEhSE9P\nx5gxY+Dk5PRQ+5c3zd7eHv3798ecOXOQnp6ON954Ay+//LLF2zW1Wi1GjRqFkSNHIicnB02bNkV6\nejri4uLg5uaGvn37YtKkSQgJCUHt2rWRmZmJr7/+GrVq1bLax0e9fDB+/Hi0b98ePj4++OOPP7B6\n9Wrs3bsXu3btAgB4eHjkuy22TJkyqFChAmrUqGGWfvbsWfzwww9Wf+dg0aJFCAsLg1arxa5du4zB\njulvXbz33nuIiIgw/sbB7Nmz8eWXXz5xvyVCJaskggINgEMi8q7+daJSqg6AwdAtPrRo5MiR+Q4y\nvXr1Qq9evUqgi2TN1KlTsX79erMvgoCAACxevBjR0dGYPn06XnzxRYwePRoff/xxgXUV5o4FpRRm\nzpyJmTNnIjExEdWrV8dXX31lPNBWrFgRcXFxGDt2LMLDw5GVlQVfX19EREQY6yrsl9bw4cNx69Yt\njBo1CteuXUOtWrXw1Vdfwd/fv8A+5zVq1ChERkaiVq1ayMzMxLlz56yWnTt3Ll599VU0adIEZcuW\nxdixY/HHH388cEzyKkyegowdOxapqano378/bGxs8Nprr6Fdu3awtbX+FVC3bl3s3bsXEyZMQPPm\nzSEi8Pf3N54dr1y5Ejt27MCRI0eg0Wjg5OSElStXolmzZujUqRPCw8Px6aefYtCgQQgJCUGVKlUQ\nHR2db91KYfbXUlqNGjXwwgsvoEOHDrh58yY6deqERYsWWd2fadOmoXz58pg5cyZ+/fVXuLu7Izg4\nGOPHjwegmwEaP348zp8/D0dHRzRr1gxr1661PqiP6Nq1a+jfvz9SUlLg5uaGevXqYdeuXWjVqpXV\nMtbe92XLlsHHx8fimT8AHDp0CJMnT0ZGRgYCAgLwySefoHfv3mZ5tm/fjujoaGRlZeGZZ57B1q1b\n0a5du4ffQSp2a9euzfeZzPsbM49KFcdZi1mFSp0HsEtE/m2SNhjABBGpYiF/MID4+Ph4TlMRPSYi\ngsDAQLz88suYMmVKaXenyKZMmYItW7YgISGhtLtCVKoSEhIMC5xDROSR/0GUxExBHIC8F/VqgosN\niUrNxYsXsWvXLjz33HPIzMzEf//7X5w/fz7f2SIR/bOVxL0mHwBorJR6Wynlr5TqDWAggP+WQFtE\nVAgajQbLly9Hw4YN0axZMxw/fhwxMTEWF+UR0T9XsV8+AAClVAcAMwFUB3AOwPsi8pmVvLx8QERE\n9BD+CpcPICLbAGwribqJiIioZPCnqoiIiAgAgwIiIiLSY1BAREREABgUEBERkR6DAiIiIgLAoICI\niIj0GBQQERERAAYFREREpMeggIiIiAAwKCAiIiI9BgVEREQEgEEBERER6TEoICIiIgAMCqgUXbhw\nARqNBr/88ktpd8Xo1KlTCA0NhaOjY6n/V95P4vg8iaZMmYKgoKDS7gbR3wKDgn+wyMhIaDQazJ49\n2yx9y5Yt0Ggez0dDKfVY2imsSZMmQavV4syZM4iJibGYp2XLlnjzzTeLtd0BAwbghRdeMEvz8fHB\n1atXUadOnWJt6+/oSfscmUpKSkL37t1RtWpVaDQaLFiwIF+eGTNmoGHDhnB1dYW3tze6deuG06dP\n58t34sQJdOnSBe7u7tBqtWjUqBEuX75s3D548GBUr14dTk5OKF++PLp27YpTp06Z1XHz5k306dMH\nbm5u8PDwwMCBA3H79u3i33H6S2JQ8A+mlIKjoyNmzZqF9PT0fNseBxEp9jrv37//0GWTk5PRtGlT\nVK5cGR4eHsXYq6JTSqF8+fKPLUCjknHnzh34+/tj1qxZqFixosU8sbGxiIqKwsGDB7F7927cv38f\n7dq1w927d415kpOT0axZM9SqVQs//PADjh49infffRcODg7GPA0aNMDy5ctx8uRJ7Nq1CyKC8PBw\ns39nvXv3xokTJxATE4NvvvkGP/zwAwYNGlRyA0B/LSJSqg8AwQAkPj5e6PGKjIyUzp07S61atWTM\nmDHG9M2bN4tGozG+njx5stSvX9+s7Lx588TPz8+srq5du0p0dLR4e3uLu7u7TJs2TbKzs2X06NHi\n6ekplStXlmXLlhnLnD9/XpRSsm7dOgkLCxMHBwepU6eO7N2716yto0ePSvv27UWr1Yq3t7f07dtX\nfv/9d+P2Fi1ayLBhw2TEiBFStmxZadWqlcX9zc3NlSlTpkjlypXF3t5e6tevLzt27DBuV0qJRqMx\n/p0yZYrFMcub78KFC4Xq55dffil169YVR0dH8fLykrZt28qdO3dk8uTJ+ercu3evcXwSExNFROT7\n778XpZTExMRIgwYNxMnJScLCwuT06dNmfZw2bZqUL19e3NzcZNCgQfL222/ne//yKqjv169flwoV\nKsiMGTOM+ePi4sTOzk727NkjIiLJycnSpUsX8fb2Fq1WK88++6zs3r3brA0/Pz+ZPn269OvXT7Ra\nrfj6+srWrVvl+vXr0qVLF9FqtVKvXj356aefjGWWL18u7u7usnnzZqlRo4Y4ODhIeHi4XLp0yZhn\n8uTJEhQUZNbWJ598IoGBgeLg4CCBgYGyePFi47Z79+7J0KFDpWLFiuLg4CB+fn4yc+bMAsenuPj5\n+cn8+fMfmO/69euilJLY2FhjWs+ePaVfv35Fau+XX34RjUYjv/76q4iIJCUliVJKEhISjHl27Ngh\nNjY2kpKSUqS66ckQHx8vAARAsBTHMbk4KnmkDjAoKDWRkZHSrVs32bx5szg6Ospvv/0mIpaDgrxf\nuvPmzZOqVaua1eXq6ipRUVFy+vRpWbZsmSilJCIiQmbMmCFnz56V6dOni52dnbEdw0HPx8dHNm3a\nJCdPnpTXXntNXF1d5caNGyIikpaWJuXLl5d33nlHTp8+LUeOHJHw8HCzA3+LFi3E1dVVxo4dK6dP\nn853kDSYO3euuLu7yxdffCGnT5+WsWPHip2dnZw9e1ZERFJTU6VOnToyevRoSU1Nldu3b+erIz09\nXcLCwmTQoEFy7do1SU1Nldzc3Af2MyUlRcqUKSPz58+XCxcuyLFjx2TJkiVy+/ZtycjIkJdfflk6\ndOhgrPP+/fty/vx50Wg0+YKC0NBQiY2NlRMnTkjz5s2ladOmxv6tWrVKHB0dZcWKFXLmzBmZOnWq\nuLm55Xv/TBVmjLdt2yZ2dnYSHx8vf/zxh/j7+8uoUaOM2xMTE+Xjjz+WpKQkOXv2rEycOFGcnJzM\nDt5+fn5StmxZ+eSTT+Ts2bMydOhQcXNzkw4dOsiGDRvkzJkz0q1bN6ldu7axzPLly8XOzk4aNmwo\nBw8elISEBGnUqJHZPuf9fK5atUqeeuop2bx5s5w/f142bdokZcuWlc8//1xERObMmSO+vr4SFxcn\nFy9elLi4OFm3bp3V8Vm9erVotVqrDxcXF9m3b5/V8qYKGxScOXNGNBqNHD9+XER0Aa2Li4tMmzZN\nwsPDpXz58tKoUSPZvHmz1ToyMjJkxIgRUr16dbl//76IiHz22Wfi6elpli87O1tsbW0LrIueXAwK\nqNgYggIRkdDQUBk4cKCIPHxQYPpaRCQgIECee+454+ucnBzRarWyfv16EfkzKJgzZ44xT3Z2tlSp\nUsWYNn36dImIiDCr99KlS6KUkjNnzoiILigICQl54P4+9dRT+c4IGzZsKMOGDTO+rl+/vsUZAlMt\nWrSQkSNHmqU9qJ8JCQmi0Wjk4sWLFus0fS8MLM0UaDQa+e6774x5tm3bJhqNRrKyskREpHHjxjJ8\n+HCzepo2bVpgUFCYMRYRGTZsmNSsWVP69OkjzzzzjNy7d89qnSIiderUkUWLFhlf+/n5Sf/+/Y2v\nr169KkopmTx5sjHtwIEDotFoJDU1VUR0QYFGo5HDhw8b85w8eVKUUsa0vJ/P6tWr5zvIT58+XZo0\naSIiIsOHD5c2bdoU2HdTGRkZkpycXOAjMzOzUHUVJijIzc2V559/Xpo3b25MM4yVVquV+fPnS2Ji\nosycOVM0Go388MMPZuUXL14sWq1WlFISGBhonCUQEYmOjpaAgIB8bZYvX14+/PDDQu0DPVmKOyiw\nLYUrFvQEmjVrFlq3bo1Ro0Y9dB21a9c2e+3t7Y26desaX2s0Gnh5eeHatWtm+Ro3bmx8bmNjgwYN\nGuDEiRMAgMTEROzZswcuLi5mZZRSSE5ORvXq1QEAISEhBfbtjz/+wJUrVxAWFmaW3qRJk2JZ3f+g\nfrZt2xatWrVCnTp1EB4ejnbt2qF79+5wd3cvclumY2q4Rn3t2jVUrlwZp06dwtChQ83yN2zYEN99\n991D990wxnPmzEGdOnWwYcMGJCQkoEyZMsa8t2/fxqRJk7Bt2zakpKQgOzsbmZmZuHjxotW+e3t7\nA4DZQkpvb2+ICK5du4by5csDAGxtbdGgQQNjnpo1a8Ld3R0nTpwwSwd01++Tk5Px6quvYuDAgcb0\nnJwc41hHRkaibdu2qFmzJiIiItCxY0e0bdvW6vg4OzujWrVqVrcXtyFDhiApKQlxcXHGtNzcXABA\n165dMXz4cABAvXr1sH//fnz44Ydo1qyZMe8rr7yCdu3aISUlBe+99x569OiB/fv3w87O7rHtA/11\nMSggAECzZs0QHh6OcePGITIy0mybRqMxzOoYWVrMZ3qQAHQHFUtphi+4wsjIyEDnzp0xe/bsfH0w\nXbTl7Oxc6DpLwoP6qdFo8O233+LHH3/Erl27sHDhQkyYMAGHDh2Cr69vkdoyHVPDgtCijGlR+25w\n9uxZXLlyBbm5uTh37hxq1apl3PbWW28hJiYG77//Pvz9/eHo6IgXX3wR9+7ds9r3ktifjIwMAMDS\npUvRsGFDs202NjYAgKCgIJw/fx7bt2/H7t278dJLL6Ft27b44osvLNa5Zs2aAhfiKaWwfft2NGnS\n5KH6bGrYsGHYtm0bYmNjzca+bNmysLW1RWBgoFn+wMBAs+ABAFxcXODi4gJ/f380atQIHh4e2LRp\nE15++WVUqFAhX1Cek5ODGzduoEKFCo/cf/rrY1BARjNmzED9+vVRs2ZNs/Ry5crh6tWrZmk///xz\nsbV74MABNG3aFIDuCyo+Pt54NhQcHIyNGzfC19f3kVbhu7i4oFKlSoiLizM7q4qLi0OjRo2KVJed\nnR1ycnLM0grbz9DQUISGhuLdd9+Fr68vNm3ahBEjRlis82HUrFkThw8fxiuvvGJMO3z4cIFlCtP3\n+/fvo2/fvujZsydq1qyJV199FceOHUPZsmUBAPv370dkZCQ6d+4MQHdwPn/+/CPvDwBkZ2fjp59+\nMs4KnDp1CmlpaWZBiUH58uVRqVIlJCcno2fPnlbr1Gq16NGjB3r06IEXX3wR7du3R1pamsWZmy5d\nupjNZlny1FNPFXGv8hs2bBi2bNmCvXv3wsfHx2xbmTJl8Oyzz+a7vfD06dMFBpW5ubkQEWRlZQHQ\nff7S0tLw888/G3/bISYmBiJS5H8H9PfEoICM6tSpgz59+uS7j7pFixYYNmwYZs+eje7du2P79u3Y\nsWMH3NzciqXdRYsWoXr16ggMDMTcuXORlpaGAQMGAACGDh2KpUuXomfPnhgzZgw8PT1x5swZrF+/\nHp9++mmRbp0cPXo0Jk+ejGrVqqF+/fr47LPPkJiYiDVr1hSpv35+fjh48CAuXLgArVYLLy+vB/bz\n8OHDiImJQbt27VC+fHkcOHAAv//+u/HA5ufnh127duH06dPw8vKyOrZ5z+TzpkVFReG1115DSEgI\nwsLCsG7dOvzyyy/w9/e3uj+FGePx48fj1q1bWLhwIZycnLBt2zYMGDAAX331FQCgRo0a2LhxIzp2\n7AgAmDhxosW+PgxbW1tERUVh/vz5sLGxQVRUFMLCwqxeMpoyZQreeOMNuLq6IiIiAllZWfjpp5+Q\nlpaGESNG4IMPPkDFihURFBQEpRS++OILVKhQweqlnEe9fHD//n0kJSVBRHDv3j389ttvSExMhFar\nNb4vQ4YMwdq1a7F161Y4OzsjNTUVAODm5ma85XD06NHo2bMnmjVrhpYtW2L79u34+uuvsXfvXgDA\nuXPnsH79erRr1w7lypXDpUuXMHPmTDg5OaFDhw4AgICAAISHh+O1117DkiVLcO/ePURFRaFXr16c\nKSCd4liY8CgPcKFhqbG2uM3e3l5sbGzM0j/66CPx9fUVFxcXiYyMlBkzZuRbaJi3rpYtW+ZbkFe1\nalXjQivD6vp169ZJo0aNrN6SePbsWXnxxRfF09NTnJ2dpVatWvLmm28W2I4lubm5MnXqVKlSpYrY\n29tLUFCQ7Nq1yyxPUFDQAxcanj59WsLCwsTJycnslsSC+nnixAmJiIgQb29vcXR0lICAALPb5K5f\nvy7h4eHi4uJidkti3rsPNBqNpKenG8sdOXLErA8iukV15cuXF1dXVxk4cKC88cYbEhYWVuA+Wer7\nW2+9ZWzXzs5O9u/fb8x//vx5cXd3Ny5OO3/+vLRu3VqcnZ3F19dXFi9enO99MX3vDTQajWzZssWs\nXtN9Xr58uXh4eMimTZvE399fHB0dC3VL4tq1ayUoKEgcHBzEy8tLWrRoYVxd/8knn0hQUJC4uLiI\nu7u7tG3bVo4cOVLg+DwKw4JRjUZj9mjZsqUxj6XtGo1GVqxYYVbXsmXLpEaNGuLk5CRBQUHy1Vdf\nGbdduXJFOnToIBUqVBB7e3vx8fGRV155Jd/dODdv3pQ+ffqIq6uruLu7y8CBAy3eaUN/DcW90FBJ\nMUXzD0spFQwgPj4+vtR/Vpbo76hdu3aoWLEiVqxYUdpdKbIVK1Zg5MiRuHHjRml3heiJlJCQYJg1\nCxGRhEetj5cPiP5G7t69iw8//BDh4eHQaDRYu3YtYmJisHv37tLuGhH9BTAoIPobUUph27ZtiI6O\nRmZmJmrWrImNGzeiZcuWpd01IvoLYFBA9Dfi4OCAb7/9trS7UWz69++P/v37l3Y3iP4x+D+tEBER\nEQAGBURERKTHoICIiIgAMCggIiIiPQYFREREBIBBAREREekxKCAiIiIADAqIiIhIj0EBERERAWBQ\nQERERHoMCoiIiAgAgwIiIiLSY1BAREREABgUEBERkR6DAvpbqVq1KhYsWFDa3cinZcuWePPNN0u7\nGyXm/v37qFGjBg4cOFDaXSlVJ06cQJUqVXD37t3S7grRQ2FQ8A82YMAAvPDCC6XdjVK1YsUKeHh4\nlHY3/vKWLFmCatWqoXHjxsa0Ll26wNfXF46OjqhUqRL69euHlJQU4/ZffvkFvXv3ho+PD5ycnFC7\ndu2HCug2bdqEZ599Fh4eHtBqtQgKCsKqVavM8syYMQMNGzaEq6srvL290a1bN5w+fbrIbT1onwID\nAxEaGor333+/yHUTPQkYFNA/mohAKVXa3fjLW7RoEQYOHGiW1qpVK3z55Zc4ffo0Nm7ciOTkZHTv\n3t24PT4+Ht7e3li9ejWSkpIwYcIEvP3221i8eHGR2vby8sI777yDAwcO4OjRoxgwYAAGDBiAb7/9\n1pgnNjYWUVFROHjwIHbv3o379++jXbt2RT6jt7RPPXr0MMsTGRmJJUuWIDc3t0h1Ez0RRKRUHwCC\nAUh8fLzQ4xUZGSndunUzvm7RooVERUXJiBEjxMPDQ7y9vWXp0qVy+/ZtGTBggLi4uEj16tVl+/bt\nxjI5OTny6quvStWqVcXR0VFq1qwp8+fPN2snOztboqKixN3dXcqVKyfjx4+X/v37S9euXY15cnNz\nJTo62lhP/fr1ZcOGDQX2/9q1a9KxY0dxdHSUatWqyerVq8XPz8+s/blz50rdunXF2dlZqlSpIkOG\nDJHbt2+LiMj3338vSinRaDTGv1OmTBERkZUrV0qDBg3ExcVFKlSoIL1795Zr164V2J9FixZJjRo1\nxMHBQby9vaVHjx5mY/vGG2/ImDFjxNPTUypUqCCTJ082K2+prxkZGcbty5cvF3d3d9m8ebOxnfDw\ncLl06ZJZPZs3b5bg4GBxcHAQf39/mTJliuTk5BTY90dx+PBhsbW1NeurJVu3bhUbGxvJzs62mmfo\n0KHSunXrR+5TcHCwTJw40er269evi1JKYmNjH6kdS/t07949cXBwkD179jxS3USFER8fLwAEQLAU\nwzGZMwVk5vPPP0e5cuVw+PBhDB8+HIMHD0aPHj3QpEkT/Pzzz2jXrh369euHzMxMAEBubi6qVKmC\n//3vfzhx4gQmTZqECRMmYMOGDcY6Z86cibVr12LFihXYt28fbt68ic2bN5udoUdHR2PVqlX4+OOP\nkZSUhJEjR6Jv376IjY212tf+/fvjt99+w969e7FhwwYsXrwY169fN8tjY2ODhQsXIikpCZ9//jm+\n++47jBkzBgAQFhaGefPmwdXVFampqUhJScGoUaMAANnZ2Zg+fTp++eUXbNmyBRcuXMCAAQOs9iU+\nPh5vvPEGpk+fjtOnT2Pnzp1o3ry5WZ4VK1ZAq9Xi0KFDmD17NqZOnYqYmJgC+zp27FizOu7cuWMc\nq/379yMtLQ29evUybo+NjUX//v0xcuRInDx5Eh999BFWrFiB//znP1b7vmbNGri4uFh9uLq6Ii4u\nzmr5ffv24emnn4azs7PVPDdu3MDq1avRpEkT2NjYWM2Xnp4OT09Pq9sLIyYmBqdPn8Zzzz1nNU9a\nWhqUUo/UlrV9KlOmDOrXr1/gZ5foiVUckUVBDwDjAOQCmGtlO2cKSomlmYLmzZsbX+fk5IhWq5X+\n/fsb065evSpKKTl48KDVeocNG2Z2llyhQgWZO3euWb2+vr7GtrOyssTZ2VkOHDhgVs/AgQOlT58+\nFts4ffq0KKXMPjcnT54UpVS+mQpTGzZskHLlyhlfL1++XDw8PKzmNzh8+LBoNBrjLENeGzduFHd3\nd6tny3nHVkSkYcOG8vbbbxeprxqNRg4fPmxMM+yzIa1NmzYyc+ZMs3pWrVollSpVstpORkaGJCcn\nF/jIzMy0Wn7EiBHSpk0bi9vGjh0rzs7OopSSsLAwuXHjhtV64uLixM7OTnbv3m01jzXp6emi1Wql\nTJky4ujoKMuWLbOaNzc3V55//vl870dhFWafXnjhBfnXv/71UPUTFUVxzxTYlmTAoZR6FsC/ASSW\nZDtUfOrVq2d8rtFo4OXlhbp16xrTvL29AQDXrl0zpi1atAjLli3DxYsXcffuXdy7dw9BQUEAgFu3\nbiE1NRXPPvusWb0hISGGoBBnz57FnTt30LZtW2MaoFvRbqgnrxMnTqBMmTIIDg42ptWsWRPu7u5m\n+Xbv3o2ZM2fi5MmTuHXrFrKzs5GVlYXMzEw4ODhYHYf4+HhMmTIFiYmJuHnzpvH68MWLFxEQEJAv\nf9u2beHr64uqVasiIiICERER6NatGxwdHY15TMcWACpWrGg2joXpq62tLRo0aJBvn0+cOIEGDRog\nMTER+/fvx/Tp0415cnJycO/ePav77OzsjGrVqlkdiwe5e/eu1bEcM2YMBg4ciAsXLmDKlCno27cv\nvv7663z5jh07hq5du2Ly5Mlo3bp1kfvg4uKCxMREZGRkICYmBiNHjkS1atXyzdYAwJAhQ5CUlFTg\n7EdBCrNPjo6OuHPnzkPVT1SaSiwoUEppAawCMBDAuyXVDhWvMmXKmL1WSuVLA2A8SK5btw6jR4/G\nBx98gMaNG8PFxQWzZ8/GoUOHCt1mRkYGAGDbtm2oVKmS2TZ7e/ui7oLRhQsX0KlTJwwdOhTR0dHw\n9PREbGwsBg4ciHv37lk9kN25cwcRERFo37491qxZg3LlyuHChQuIiIjAvXv3LJbRarVISEjA999/\nj127dmHSpEmYPHkyfvrpJ7i6ugKwPLaGcXzYvuaVkZGBqVOnWryrxFoda9aswaBBg6zWqZTC9u3b\n0aRJE4vby5Yti2PHjlnc5unpCU9PT1SvXh0BAQGoUqUKDh48iEaNGhnzJCUloU2bNhg8eDDefvvt\ngnavwD4aApt69eohKSkJM2bMyBcUDBs2DNu2bUNsbCwqVqz4UG0VZp9u3LiB6tWrP1T9RKWpJGcK\nFgH4SkT2KKUYFPxN7d+/H02aNDE7qCQnJxufG24BO3z4MJo2bQpAF1AkJCQYZwFq1aoFe3t7XLhw\nwZjnQQICApCdnY34+HiEhIQAAE6dOoW0tDRjnvj4eIgI3nvvPWPaunXrzOqxs7NDTk6OWdrJkydx\n48YNzJgxA0899RQAFCrI0Wg0aNWqFVq1aoWJEyfC3d0de/bsQdeuXR9YtjB9BXRrHX766SfjbIFh\nn2vVqgUACA4OxqlTp4p05t+lSxezWwktMYyDJUFBQfjwww8f2I5hnLOysoxpx48fR+vWrTFgwABM\nnTq1kD1+sNzcXLN2AF1AsGXLFuzduxc+Pj7F0o6lfQJ0Mx9570og+isokaBAKdUTQH0ADR6Ul/7a\natSogZUrV2LXrl2oWrUqVq5cicOHD5sdlKKiohAdHQ1/f38EBARg4cKFxoVegO4se9SoURg5ciRy\ncnLQtGlTpKenIy4uDm5ubujbt2++dp9++mmEh4fj3//+N5YsWQIbGxuMHDkSTk5OxjzVq1fH/fv3\nsWDBAnTq1An79u3DRx99ZFaPn58fMjIysGfPHjzzzDNwcnKCj48P7OzssGDBAgwePBhHjx41m463\n5JtvvsGvv/6K5s2bw8PDA9988w1ExOKlBksK01dAd/kgKioK8+fPh42NDaKiohAWFmYMjCZOnIhO\nnTqhSpUq6N69OzQaDRITE3Hs2DFMmzbNYtuPevmgZcuWyMjIQFJSkjE4OXTokDEQ9PDwwNmzZzFx\n4kTUqFEDoaGhAHQHzlatWqF9+/YYMWIEUlNTAegWXJYtW7bQ7c+cORMNGjSAv78/srKy8M0332DV\nqgnnGhIAABc3SURBVFVmgcqQIUOwdu1abN26Fc7Ozsa23NzcCj0LU5h9AnSzPleuXEGbNm0KvQ9E\nT4ziWJhg+gBQGcBVAHVM0r7DAxYaNm/eXDp16mT2WLNmTXGvySATeRcatmzZUkaOHGmWp2rVqvkW\n7mk0GtmyZYuI6BYJ/utf/xIPDw/x9PSUoUOHyvjx4yUoKMiYPzs7W4YPHy7u7u7i5eUl48aNk5de\nekl69+5tVu+CBQskMDBQ7O3txdvbW9q3b1/gLWOpqanSqVMncXR0FD8/P1m1alW+/s6bN0+eeuop\ncXZ2lvbt28uqVatEo9FIenq6Mc+QIUOkbNmyZrckrlu3TqpVqyaOjo7SpEkT+frrr0Wj0UhiYqLF\nvuzbt09atGghXl5e4uzsnO+WSktj27VrVxkwYECh+2pYFLlp0ybx9/cXR0dHi7ck7tq1S5o2bSrO\nzs7i7u4ujRs3lqVLl1odx+LQs2dPs0WTR48elVatWknZsv/f3p0HR1nlaxz//jpkIGEN4DUwLIYE\nISAFJC6DYRNQ0FKUUkSgSkAjcAVk8BLAAgkglyWOggvUXEsR0QHiwuhQXgYVFCGaARMMIGFEBGEm\nIgoKorIYzv2j3/RNSIIs3WlInk9VV9mn3z7n1y+x36fPuzUMnDI6atQoV1BQEFhm2rRpzufzlXrE\nxcWV6NvM3EsvvVTu2FOmTHFXXnmli46Odg0aNHApKSnutddeK9VHWWMV7zc9Pd1dccUV5Y5zNp/J\nOedmzZrlbr755jOvMJHzsHTp0lLbya5duwb1QENzxQ7sCgYzux1YARQCReecRXhFFwLVXbFBzSwJ\nyMnJySlx0JhUXs45EhMTGTBgANOnTw93OZeMl156iXHjxnHo0KFwl1LK1q1buemmm9i1a1eJ2ZoL\ntXv3blq3bs327duJj48PWr9lGTp0KBEREbzwwgvn3UfR5Z6XL1/+m7tkRIIhNze3aKYw2TmXe6H9\nhWL3wXtAu9PaFgP5wBwX7BQiF729e/fyzjvv0K1bN44dO8azzz7Lnj17GDRoULhLkyBp164dc+fO\nZffu3bRt2zZo/a5atYrhw4eHPBAArFu37rzPSCiyd+9eJk+erEAgl6yghwLn3E/A9uJtZvYTcNA5\nlx/s8eTi5/P5WLx4MWlpaTjnuOqqq1izZg2tWrUKd2kSRPfee2/Q+3zwwQeD3md5du/efcF9xMfH\nV0iAEQmVkF6noBjNDlRhTZo0YcOGDeEu45I3ZMgQhgwZEu4yRKQSq5BQ4JzrURHjiIiIyPnTvQ9E\nREQEUCgQERERj0KBiIiIAAoFIiIi4lEoEBEREUChQERERDwKBSIiIgIoFIiIiIhHoUBEREQAhQIR\nERHxKBSIiIgIoFAgIiIiHoUCERERARQKJIy++uorfD4fW7ZsCXcpAf/85z/p1KkTUVFRJCUlnfP7\nL8bPJCJythQKqrChQ4fi8/nIyMgo0f7WW2/h81XMn4aZVcg4Zys9PZ1atWqxc+dO1qxZc159XGyf\nKRy++OILateuTf369Uu0Z2Vl0blzZxo2bEh0dDSJiYnMnz8/TFWKyOkUCqowMyMqKoq5c+dy+PDh\nUq9VBOdc0Ps8efLkeb93165ddO7cmSZNmhATE3NefYTiM11Kfv31VwYNGkS3bt1KvVazZk3GjBnD\n+vXr2bFjB48++ihTpkzh+eefD0OlInI6hYIqrlevXsTGxjJr1qxyl5k+fTodO3Ys0fbUU08RFxcX\neD5s2DD69evH7NmziY2NJSYmhpkzZ1JYWMiECRNo0KABTZs2ZfHixaX6z8/PJyUlhaioKNq1a8eH\nH35Y4vVt27Zxyy23ULt2bWJjY7n33ns5ePBg4PUbbriBMWPGMG7cOC677DL69OlT5udwzjFjxgya\nNm1KjRo16NixI6tXrw687vP5yM3NZfr06URERDBjxoxy+8nIyKBly5bUqFGDK664gtmzZ5e57KlT\np0hNTaVFixZER0fTunVrnn766RLLfPDBB1x33XXUqlWLmJgYunTpwr59+wDYsmULPXr0oE6dOtSt\nW5drrrmG3NzcwHs3bNhA165diY6Opnnz5owdO5aff/458PrChQu58soriYqKIjY2lrvvvrvMOoNp\n8uTJJCYm0r9//1KvdejQgQEDBpCYmEizZs0YNGgQvXv3Zv369SGvS0R+m0JBFRcREcGsWbN45pln\nKCgoKHe5smYOTm9bu3YtX3/9NevXr2fevHlMnTqVW2+9lfr167Nx40ZGjhzJiBEjSo0zYcIE0tLS\n+PTTT+nUqRO33XYb33//PQCHDx+mZ8+eJCcnk5uby+rVqzlw4ECpjduSJUuoXr06H330EX/+85/L\n/Azz589n3rx5PPnkk2zdupXevXvTt29fdu3aBcD+/ftp06YN48eP5+uvv2b8+PFl9jNp0iQyMjJI\nT08nPz+fzMxMYmNjy1z21KlTNG3alDfeeIP8/HzS09OZPHkyr7/+OgCFhYX069ePG264gW3btpGd\nnc3w4cMD63bw4ME0bdqUnJwccnNzmTRpEpGRkYB/VuPmm2+mf//+bNu2jczMTLKyshgzZgwAn3zy\nCWPHjmXmzJl8/vnnrF69mq5du5ZZJ8C+ffuoXbt2uY86deowZ86cct8P/r+BN954gwULFpxxuSKb\nN2/m448/pnv37me1vIiEmHMurA8gCXA5OTlOKtbQoUNdv379nHPOderUyaWmpjrnnHvzzTedz+cL\nLDdt2jTXsWPHEu+dP3++i4uLK9FX8efOOde6dWvXrVu3wPPCwkJXq1Ytl5mZ6Zxzbs+ePc7M3OOP\nPx5Y5tdff3VNmzYNtM2cOdP16dOnRL/79u1zZuZ27tzpnHOue/fuLjk5+Tc/7+9//3s3Z86cEm3X\nXnutGz16dOB5hw4d3PTp08vt48cff3Q1atRwixYtKvP1os+Ul5dXbh+jR492/fv3d845d+jQIefz\n+dyHH35Y5rJ16tRxS5YsKfO11NRUN3LkyBJt69evdxEREe748eNuxYoVrl69eu7o0aPl1lJcYWGh\n27Vr1xkf33//fbnv/+6771yzZs3chg0bnHPOLV682MXExJS5bJMmTVz16tVdtWrV3MyZM8+qPhEp\nLScnxwEOSHJB2CZXC2sikYvG3Llz6dmzZ7m/js9G27ZtSzy//PLLadeuXeC5z+ejQYMGHDhwoMRy\nf/jDHwL/HRERwdVXX01+fj4AeXl5rF27ltq1a5d4j5mxa9cuEhISAEhOTj5jbT/++CMFBQVcf/31\nJdpTUlLO6UyB/Px8Tpw4QY8ePc76PQsWLODFF19k7969/PLLL5w4cSKwOyYmJoYhQ4Zw0003ceON\nN9KrVy/uvvvuwMzDww8/zP3338+SJUvo1asX/fv3p0WLFoB/3WzdupVXXnklMJbzjmfYvXs3N954\nI82aNSMuLo4+ffrQp08f+vXrR1RUVJl1+ny+QN/n44EHHmDw4MGkpKSUqKUsGzZs4OjRo2RnZzNx\n4kQSEhIYMGDAeY8tIsGh3QcCQJcuXejduzeTJk0q9ZrP5yv1BV/WwXxF09pFzKzMtlOnTp11XUeP\nHqVv375s2bKFvLy8wGPnzp0lpsJr1qx51n1eiPI2qOVZvnw5aWlpPPDAA7z77rvk5eUxbNgwTpw4\nEVhm0aJFZGdnk5KSQmZmJq1atWLjxo2A/2yI7du3c+utt7J27VratGnDW2+9BfjXzYgRI0qsmy1b\ntvD5558THx9PrVq12Lx5M8uXL6dx48akp6fTvn17jhw5UmatRbsP6tSpc167D95//33+9Kc/ERkZ\nSWRkJKmpqfzwww/87ne/K3UsSfPmzWnbti33338/48aNY9q0aee0XkUkNDRTIAGzZ8+mQ4cOtGrV\nqkT7ZZddxv79+0u0bd68OWjjZmdn07lzZ8C/jz0nJ4eHHnoIgKSkJFasWEHz5s0v6DTJ2rVr07hx\nY7KysujSpUugPSsri+uuu+6s+yk6uHDNmjXcd999v7n8Rx99REpKCiNGjAi0FR3DUFz79u1p3749\nEydO5Prrr2fp0qVce+21ACQkJDB27FjGjh3LoEGDePHFF7n99ttJSkpi+/btJQ74PJ3P56NHjx70\n6NGDqVOnUq9ePdauXcsdd9xRatnGjRuTl5d3xs9z+imGxWVnZ1NYWBh4/uabb5KRkcHHH39M48aN\ny31fYWEhx48fP+O4IlIxFAok4KqrrmLw4MGljo7v3r07o0ePJiMjg7vuuotVq1bx97//nbp16wZl\n3AULFpCQkEBiYiJPPvkkP/zwA8OGDQNg1KhRPP/889xzzz1MmDCB+vXrs3PnTjIzM3nhhRfO6dTJ\ntLQ0pk2bRosWLejQoQOLFi0iLy+PpUuXnnUf1atXZ+LEiUyYMIHIyEhSUlL49ttv+eyzz8oMCS1b\ntuTll1/mnXfeIS4ujpdffplNmzYFpun37NnDc889R9++fWncuDE7duxg586dDB06lGPHjpGWlsZd\nd91FXFwc+/btY9OmTYGj+idOnEinTp0YM2YMqamp1KxZk88++4z33nuPZ555hrfffpsvv/ySrl27\nEhMTw9tvv41zrlToKxIREXFBuw9O73fTpk34fD4SExMDbQsXLqRZs2a0bt0agHXr1vHEE0/wxz/+\n8bzHFZHgUSiQEmbMmEFmZmaJjW3r1q1ZuHAhs2bNYubMmdx5552kpaXx3HPPnbGvszljwcyYM2cO\nc+bMIS8vj4SEBFauXBn4RdqoUSOysrKYOHEivXv35vjx4zRv3pw+ffoE+jrbYPDQQw9x5MgRxo8f\nz4EDB2jTpg0rV64kPj7+jDWfburUqURGRpKenk5BQQGNGjVi5MiRZfYxYsQIPv30U+655x7MjIED\nBzJq1ChWrVoFQHR0NDt27GDJkiUcPHiQRo0aMWbMGIYPH87Jkyc5ePAgQ4YM4ZtvvqFhw4bceeed\ngan2du3asW7dOiZPnkzXrl1xzhEfHx/YN1+vXj1WrFjB9OnTOXbsGC1btmT58uUlNtIV7dSpUzzy\nyCPs2bOHatWqER8fz+OPP87w4cPDVpOI/D8708FAFVKAWRKQk5OTc16XlRUREamqcnNziw60TnbO\n5f7W8r9FBxqKiIgIoFAgIiIiHoUCERERARQKRERExKNQICIiIoBCgYiIiHgUCkRERARQKBARERGP\nQoGIiIgACgUiIiLiUSgQERERQKFAREREPAoFIiIiAigUiIiIiEehQERERACFAhEREfEoFIiIiAig\nUCAiIiIehQIREREBFApERETEo1AgIiIigEKBiIiIeIIeCszsETPbaGZHzOwbM/urmV0Z7HFEREQk\nuEIxU9AFeAa4DugFRALvmFlUCMYSERGRIKkW7A6dc7cUf25mQ4EDQDKwIdjjiYiISHBUxDEF9QAH\nHKqAsUREROQ8hTQUmJkB84ENzrntoRxLRERELkzQdx+cZiHQBkj5rQXHjRtH3bp1S7QNHDiQgQMH\nhqg0ERGRS8eyZctYtmxZibbDhw8HdQxzzgW1w0DHZs8CtwFdnHN7z7BcEpCTk5NDUlJSSGoRERGp\njHJzc0lOTgZIds7lXmh/IZkp8ALB7UC3MwUCERERuXgEPRSY2UJgINAX+MnMLvdeOuycOxbs8URE\nRCQ4QnGg4UigDvABUFDscXcIxhIREZEgCcV1CnTpZBERkUuQNuAiIiICKBSIiIiIR6FAREREAIUC\nERER8SgUiIiICKBQICIiIh6FAhEREQEUCkRERMSjUCAiIiKAQoGIiIh4FApEREQEUCgQERERj0KB\niIiIAAoFIiIi4lEoEBEREUChQERERDwKBSIiIgIoFIiIiIhHoUBEREQAhQIRERHxKBSIiIgIoFAg\nIiIiHoUCERERARQKRERExKNQICIiIoBCgYiIiHgUCkRERARQKBARERGPQoGIiIgACgUiIiLiUSgQ\nERERQKFAREREPAoFIiIiAigUiIiIiEehQERERACFAhEREfEoFIiIiAigUCAiIiIehQIREREBFApE\nRETEo1AgIiIigEKBiIiIeBQKREREBFAoEBEREY9CgYiIiAAKBSIiIuJRKKiili1bFu4Sqhyt84qn\ndV7xtM4vbSELBWY2ysx2m9kvZpZtZteEaiw5d/oft+JpnVc8rfOKp3V+aQtJKDCzAcATQDrQEcgD\nVptZw1CMJyIiIhcuVDMF44D/cc4tcc7tAEYCPwP3hWg8ERERuUBBDwVmFgkkA2uK2pxzDngP6BTs\n8URERCQ4qoWgz4ZABPDNae3fAK3KWL4GQH5+fghKkfIcPnyY3NzccJdRpWidVzyt84qndV6xim07\nawSjP/P/iA8eM2sE/Bvo5Jz7R7H2uUBX51yn05YfBPwlqEWIiIhULYOdc0svtJNQzBR8BxQCl5/W\nfjmwv4zlVwODgT3AsRDUIyIiUlnVAK7Avy29YEGfKQAws2zgH865sd5zA/YCTzvnHg/6gCIiInLB\nQjFTAPAksNjMcoCN+M9GiAYWh2g8ERERuUAhCQXOuVe9axLMwL/b4FOgt3Pu21CMJyIiIhcuJLsP\nRERE5NKjex+IiIgIoFAgIiIinrCHAt04qeKY2SNmttHMjpjZN2b2VzO7Mtx1VSVmNsnMTpnZk+Gu\npTIzs8Zm9rKZfWdmP5tZnpklhbuuysrMfGb2mJl96a3vL8xsSrjrqkzMrIuZ/c3M/u19h/QtY5kZ\nZlbg/Ru8a2YJ5zpOWEOBbpxU4boAzwDXAb2ASOAdM4sKa1VVhBd4h+P/O5cQMbN6QBZwHOgNJAL/\nBXwfzroquUnACOBBoDUwAZhgZqPDWlXlUhP/QfsPAqUOBjSzicBo/N8x1wI/4d+e/u5cBgnrgYbl\nXM9gH/7rGWSErbAqwgtfB/BfaXJDuOupzMysFpAD/CfwKLDZOfdweKuqnMxsDv4rqnYLdy1VhZmt\nBPY75x4o1vY68LNz7t7wVVY5mdkp4A7n3N+KtRUAjzvn5nnP6+C/vcAQ59yrZ9t32GYKdOOki0I9\n/InzULgLqQIWACudc2vDXUgVcBvwiZm96u0myzWz1HAXVcl9BPQ0s5YAZtYeSAH+N6xVVRFmFgfE\nUnJ7egT4B+e4PQ3VxYvOxrneOEmCyJuVmQ9scM5tD3c9lZmZ3QN0AK4Ody1VRAv8MzJPAP+Nfyr1\naTM77px7OayVVV5zgDrADjMrxP+Dc7Jzbnl4y6oyYvH/wCtrexp7Lh2FMxRIeC0E2uBP8xIiZtYE\nf/jq5Zw7Ge56qggfsNE596j3PM/MrgJGAgoFoTEAGATcA2zHH4KfMrMCBbFLSzgPNDzXGydJkJjZ\ns8AtQHfn3NfhrqeSSwYuA3LN7KSZnQS6AWPN7IQ3YyPB9TVw+r3Y84FmYailqsgA5jjnXnPOfeac\n+wswD3gkzHVVFfsBIwjb07CFAu9XUw7Qs6jN+4LsiX//lISAFwhuB25wzu0Ndz1VwHtAO/y/nNp7\nj0+AV4D2TpcUDYUsSu+CbAV8FYZaqopo/D/yijvFRXDae1XgnNuNf+NffHtaB/+ZZue0PQ337gPd\nOKkCmdlCYCDQF/jJzIpS5WHnnG5bHQLOuZ/wT6cGmNlPwEHn3Om/ZiU45gFZZvYI8Cr+L8ZU4IEz\nvksuxEpgipn9C/gMSML/ff58WKuqRMysJpCAf0YAoIV3QOch59w+/Lspp5jZF8Ae4DHgX8Bb5zRO\nuH+omNmD+M9pLbpx0hjn3CdhLaqS8k5jKesffJhzbklF11NVmdla4FOdkhg6ZnYL/oPfEoDdwBPO\nuUXhrary8jZYjwH9gP8ACoClwGPOuV/DWVtlYWbdgPcp/R3+knPuPm+ZafivU1APWA+Mcs59cU7j\nhDsUiIiIyMVB+3tEREQEUCgQERERj0KBiIiIAAoFIiIi4lEoEBEREUChQERERDwKBSIiIgIoFIiI\niIhHoUBEREQAhQIRERHxKBSIiIgIAP8Hv2DFybg+Ba8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d60ae5278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### To start off let's do a basic data summary.\n",
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(y_train[0])\n",
    "\n",
    "### plot the basic data summary.\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Basic data summary', fontsize=14, fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "ax.text(2, 6, \"Number of training examples = \"+str(n_train))\n",
    "ax.text(2, 5, \"Number of testing examples = \"+str(n_test))\n",
    "ax.text(2, 4, \"Image data shape = \"+str(image_shape))\n",
    "ax.text(2, 3, \"Number of classes = \"+str(n_classes))\n",
    "ax.axis([0, 10, 0, 10])\n",
    "plt.savefig('output_for_readme/data_summary.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c63b62ef-f531-43ef-83f0-43bc5756c556"
    }
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization goes here.\n",
    "# Plot the number of features corresponding to a given label\n",
    "labelDistribution = {}\n",
    "for label in setOfLabels:\n",
    "    for idx, val in enumerate(X_train):\n",
    "        if original_y_train[idx] == label:\n",
    "            if label in labelDistribution:\n",
    "                labelDistribution[label] += 1\n",
    "            else:\n",
    "                labelDistribution[label] = 1\n",
    "\n",
    "labelArray = []\n",
    "featureCountByLabelArray = []\n",
    "for key, value in labelDistribution.items():\n",
    "    labelArray.append(key)\n",
    "    featureCountByLabelArray.append(value)\n",
    "\n",
    "plt.plot(labelArray,featureCountByLabelArray,'ro')\n",
    "plt.suptitle('Feature distribution  summary', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Number of features')\n",
    "plt.xlabel('labels')\n",
    "plt.savefig('output_for_readme/label_distribution.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7820b8bf-3777-4504-a4e0-f0a94a71a8e2"
    }
   },
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Your model can be derived from a deep feedforward net or a deep convolutional network.\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a7bd6deb-53ca-4895-9447-b1272b95b4a2"
    }
   },
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a7de670a-f06d-4b45-abc9-473a1c1c2a3c"
    }
   },
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe the techniques used to preprocess the data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c408af92-53aa-43a7-9d32-e2d6e7c3e8b4"
    }
   },
   "source": [
    "**Answer:**\n",
    "The data will be run through -\n",
    "- np.mean(axis=3) - this squelches the data to 32X32 from 32x32x3\n",
    "- normalize_greyscale() - this transforms the 0-255 to 0.1-0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a9bb3a45-0e53-4eb7-889b-cc6e82dc65d3"
    }
   },
   "outputs": [],
   "source": [
    "# get a reference to the index of a random traffic sign\n",
    "randomIdx = random.randint(0,len(X_train))\n",
    "randomImg = X_train[randomIdx]\n",
    "\n",
    "# show the random traffic sign before preprocessing \n",
    "fig = plt.figure()\n",
    "fig.suptitle('Random traffic sign rgb', fontsize=14, fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(randomImg)\n",
    "plt.savefig('output_for_readme/preprocess_before.jpg')\n",
    "# plt.show()\n",
    "\n",
    "### Preprocess the data here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "def normalize_greyscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    x_max = 255\n",
    "    x_min = 0\n",
    "    return  a+(((image_data - x_min)*(b - a))/(x_max - x_min)) \n",
    "\n",
    "# Preprocess training features\n",
    "onePixBeforePreProcessing = X_train[randomIdx][0][0]\n",
    "X_train = np.mean(X_train, axis=3)\n",
    "onePixAfterSquelching = X_train[randomIdx][0][0]\n",
    "X_train = normalize_greyscale(X_train)\n",
    "onePixAfterGreyScaling = X_train[randomIdx][0][0]\n",
    "\n",
    "### plot sample preprocessed values.\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Image preprocessing  summary', fontsize=14, fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "ax.text(2, 5, 'single pixel 3 rgb values      : '+str(onePixBeforePreProcessing))\n",
    "ax.text(2, 4, 'single pixel 1 mean value      : '+str(onePixAfterSquelching))\n",
    "ax.text(2, 3, 'single pixel 1 greyscale value : '+str(onePixAfterGreyScaling))\n",
    "ax.axis([0, 8, 0, 8])\n",
    "plt.savefig('output_for_readme/preprocess_summary.jpg')\n",
    "plt.show()\n",
    "\n",
    "# show the same random traffic sign after preprocessing \n",
    "fig = plt.figure()\n",
    "fig.suptitle('Random traffic sign greyscale', fontsize=14, fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(X_train[randomIdx])\n",
    "plt.savefig('output_for_readme/preprocess_after.jpg')\n",
    "# plt.show()\n",
    "\n",
    "# Apply similar Preprocessing to test features\n",
    "X_test = np.mean(X_test, axis=3)\n",
    "X_test = normalize_greyscale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3ebc687e-decf-4324-927b-0581c676aab5"
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "_Describe how you set up the training, validation and testing data for your model. If you generated additional data, why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a2413f4d-4088-4925-a015-3e924c092471"
    }
   },
   "source": [
    "**Answer:**\n",
    "we use train_test_split to use 10% of original training features to be validation set. Thus actual training occurs on 90% of the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e21911ba-4f24-4fbc-8a28-eb359a34acd9"
    }
   },
   "outputs": [],
   "source": [
    "### Generate data additional (if you want to!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "# Get randomized datasets for training and validation\n",
    "X_train_features, X_valid_features, y_train_labels, y_valid_labels = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.10,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9abed175-1a1c-4717-a41b-544171ca43d2"
    }
   },
   "source": [
    "### Question 3\n",
    "\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)  For reference on how to build a deep neural network using TensorFlow, see [Deep Neural Network in TensorFlow\n",
    "](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/b516a270-8600-4f93-a0a3-20dfeabe5da6/concepts/83a3a2a2-a9bd-4b7b-95b0-eb924ab14432) from the classroom._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b59b7425-3cca-45b0-a6fb-5b0fb677eaf2"
    }
   },
   "source": [
    "**Answer:**\n",
    "we use a variant of the leNet architecture\n",
    "- INPUT -> CONV -> ACT -> POOL -> CONV -> ACT -> POOL -> FLATTEN -> FC -> ACT -> FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "26698b43-e7cb-454b-82a7-57ab4216e91c"
    }
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "learning_rate = 0.001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "def LeNet(x):\n",
    "    # Reshape from 2D to 4D. This prepares the data for\n",
    "    # convolutional and pooling layers.\n",
    "    x = tf.reshape(x, (-1, 32, 32, 1))\n",
    "    # Squish values from 0-255 to 0-1.\n",
    "    x /= 255.\n",
    "\n",
    "    # TODO: Define the LeNet architecture.\n",
    "    # Return the result of the last fully connected layer.\n",
    "    # 28x28x6\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6)))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1 = tf.nn.dropout(conv1, dropout)\n",
    "\n",
    "    # 14x14x6\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # 10x10x16\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16)))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # 5x5x16\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Flatten\n",
    "    fc1 = flatten(conv2)\n",
    "    \n",
    "    # (5 * 5 * 16, 120)\n",
    "    fc1_shape = (fc1.get_shape().as_list()[-1], 120)\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(fc1_shape)))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1 = tf.matmul(fc1, fc1_W) + fc1_b\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 43)))\n",
    "    fc2_b = tf.Variable(tf.zeros(43))\n",
    "    return tf.matmul(fc1, fc2_W) + fc2_b\n",
    "\n",
    "\n",
    "# input data consists of 32x32, grayscale min-max scaled images.\n",
    "x = tf.placeholder(tf.float32, (None, 32,32))\n",
    "# Classify over 43 digits 0-42.\n",
    "y = tf.placeholder(tf.float32, (None, 43))\n",
    "# Create the LeNet.\n",
    "fc2 = LeNet(x)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=fc2, labels=y))\n",
    "# not using GSD as i found it to not converge quickly enough\n",
    "# opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "opt = tf.train.AdamOptimizer()\n",
    "train_op = opt.minimize(loss_op)\n",
    "correct_prediction = tf.equal(tf.argmax(fc2, 1), tf.argmax(y, 1))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# convenience next_batch function\n",
    "def next_batch(x, y, batch_index, batch_size):\n",
    "    start = batch_index + 1\n",
    "    end = start + batch_size\n",
    "    return x[start:end, :], y[start:end, :]\n",
    "\n",
    "def eval_data(features,labels):\n",
    "    \"\"\"\n",
    "    Given features and lables as input, returns the loss and accuracy.\n",
    "    \"\"\"\n",
    "    steps_per_epoch = len(features) // BATCH_SIZE\n",
    "    num_examples = steps_per_epoch * BATCH_SIZE\n",
    "\n",
    "    total_acc, total_loss = 0, 0\n",
    "    batch_index = 0    \n",
    "    for step in range(steps_per_epoch):\n",
    "        batch_x, batch_y = next_batch(features, labels,batch_index,BATCH_SIZE)\n",
    "        loss, acc = sess.run([loss_op, accuracy_op], feed_dict={x: batch_x, y: batch_y})\n",
    "        total_acc += (acc * batch_x.shape[0])\n",
    "        total_loss += (loss * batch_x.shape[0])\n",
    "        batch_index +=  BATCH_SIZE\n",
    "    return total_loss/num_examples, total_acc/num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "34b31564-5d88-4c99-95b2-c9a89c0f5ee9"
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "_How did you train your model? (Type of optimizer, batch size, epochs, hyperparameters, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cff6dda5-c57b-4307-b7b1-3234fe72a461"
    }
   },
   "source": [
    "**Answer:**\n",
    "I started with default hyperparameters of 30 epochs/64 as batch_size and x/=255 as the data sqleching. Then over a series of test varied these. Noted the validation accuracy/loss as well as the test accuracy/loss. The goal is to get the highest accuracy / least loss possible.\n",
    "Results are below \n",
    "- https://drive.google.com/file/d/0B9vOjB65N3QkOUhfMElydUZ0MEE/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('output_for_readme/test_run_results.jpg')\n",
    "f, ax1 = plt.subplots(1,1, figsize=(24,12))\n",
    "f.tight_layout()\n",
    "ax1.set_title('test_run_results', fontsize=30)\n",
    "ax1.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        steps_per_epoch = len(X_train_features) // BATCH_SIZE\n",
    "        num_examples = steps_per_epoch * BATCH_SIZE\n",
    "        print(\"begin first epoch loss calc =\", time.strftime(\"%c\"))\n",
    "        \n",
    "        # Training cycle\n",
    "        for i in range(EPOCHS):\n",
    "            batch_index = 0\n",
    "            for step in range(steps_per_epoch):\n",
    "                batch_x, batch_y = next_batch(X_train_features, y_train_labels,\n",
    "                    batch_index,BATCH_SIZE)\n",
    "                # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                loss = sess.run(train_op, feed_dict={x: batch_x, y: batch_y})\n",
    "                batch_index +=  BATCH_SIZE\n",
    "\n",
    "            #val_loss, val_acc = eval_data(valid_features,valid_labels)\n",
    "            val_loss, val_acc = eval_data(X_valid_features, y_valid_labels)\n",
    "            print(time.strftime(\"%X\"),\"{}\".format(i+1),\n",
    "                  \"loss = {}\".format(val_loss),\"accuracy = {}\".format(val_acc))\n",
    "\n",
    "        # Evaluate on the test data\n",
    "        #test_loss, test_acc = eval_data(X_test,y_test)\n",
    "        test_loss, test_acc = eval_data(X_test, y_test)\n",
    "        print(\"Test loss = {}\".format(test_loss),\n",
    "              \"Test accuracy = {}\".format(test_acc))\n",
    "        \n",
    "train_model()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1ad6dd6f-8069-4f35-8a20-3fa2e8c18d71"
    }
   },
   "source": [
    "### Question 5\n",
    "\n",
    "\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d0c49278-eef8-458c-8c19-40067e090d4c"
    }
   },
   "source": [
    "**Answer:**\n",
    "I considered doing a basic feed forward network and initially used the template supplied in the lectures. However i found the lenet architecture less verbose and easy to understand at a glance, so i adopted that one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b65ee404-5eb6-420a-acc5-6174dfabc963"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "Take several pictures of traffic signs that you find on the web or around you (at least five), and run them through your classifier on your computer to produce example results. The classifier might not recognize some local signs but it could prove interesting nonetheless.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0b24bfa9-a45c-4903-81f3-e02eabc658c4"
    }
   },
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Plot some german traffic signs obtained from the internet ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "58daad7e-070e-4579-b925-2850901593e6"
    }
   },
   "source": [
    "### Question 6\n",
    "\n",
    "_Choose five candidate images of traffic signs and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult? It would be helpful to plot the images in the notebook._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "efb60ab4-5249-4f2f-90f5-01923162caf3"
    }
   },
   "source": [
    "**Answer:**\n",
    "Five random German traffic signs were collected online and roughly cropped to be about square. each image was a jpeg. Then code was written to resize these to be 32x32x3 each.\n",
    "There is an image of a pedestrian walking that might not match exactly  in the sample set supplied, so maybe that would be off. All other are pretty crisp to start with and should generally classified to the 85% accuracy or so reported by the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_images(images, per_row=1, titles=None, main_title=None):\n",
    "    figure = plt.figure(1)\n",
    "\n",
    "    for n, img in enumerate(images):\n",
    "        ax = figure.add_subplot(np.ceil(len(images) / per_row), per_row, n + 1)\n",
    "\n",
    "        ax.grid(False)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        if (titles is not None and len(titles) >= n):\n",
    "            ax.set_title(titles[n])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n",
    "        plt.imshow(img)\n",
    "        # 'images_from_web/' below is coming from the next function\n",
    "        figure.savefig('output_for_readme/processed_Frames_'+titles[0][len('images_from_web/'):])\n",
    "    if main_title is not None:\n",
    "        plt.suptitle(main_title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_path = 'images_from_web/*.jpg'\n",
    "image_files = glob.glob(images_path)\n",
    "\n",
    "for fname in image_files:\n",
    "    img = cv2.imread(fname)\n",
    "    show_images([img], titles=[fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "bf353632-4e45-45fb-ae93-b400bd675959"
    }
   },
   "outputs": [],
   "source": [
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "newImagePaths = ['images_from_web/no_entry_cropped.jpg',\n",
    "                 'images_from_web/speed_limit_60_cropped.jpg',\n",
    "                 'images_from_web/right_of_way_cropped.jpg',\n",
    "                 'images_from_web/pedestrians_cropped.jpg',\n",
    "                 'images_from_web/road_work_cropped.jpg']\n",
    "thumbnails = []\n",
    "\n",
    "def populateImageArrayCollection(image):\n",
    "    image= image.resize((32,32),Image.ANTIALIAS)\n",
    "    thumbnailArray = np.reshape(image,(32,32,3))\n",
    "    thumbnails.append(thumbnailArray)\n",
    "    return thumbnails\n",
    "\n",
    "def populateNewImages():\n",
    "    for imagePath in newImagePaths:\n",
    "        thumbnails = populateImageArrayCollection(\n",
    "            Image.open(imagePath))\n",
    "    thumbnails = np.asarray(thumbnails,dtype=np.float32); \n",
    "    return thumbnails \n",
    "\n",
    "newImages = populateNewImages()\n",
    "# newImages above is 32x32x3 - so transform as needed, just like the\n",
    "# training set preprocessing\n",
    "newImages = np.mean(newImages, axis=3)\n",
    "newImages = normalize_greyscale(newImages)\n",
    "\n",
    "def populateOHELabelsForNewImages():\n",
    "    no_entry_cropped_label = np.zeros((1,43))\n",
    "    no_entry_cropped_label[0,17] = 1\n",
    "    speed_limit_60_cropped_label = np.zeros((1,43))\n",
    "    speed_limit_60_cropped_label[0,3] = 1\n",
    "    right_of_way_cropped_label = np.zeros((1,43))\n",
    "    right_of_way_cropped_label[0,11] = 1\n",
    "    pedestrians_cropped_label = np.zeros((1,43))\n",
    "    pedestrians_cropped_label[0,27] = 1\n",
    "    road_work_cropped_label = np.zeros((1,43))\n",
    "    road_work_cropped_label[0,25] = 1\n",
    "    return np.vstack([no_entry_cropped_label,\n",
    "                      speed_limit_60_cropped_label,\n",
    "                      right_of_way_cropped_label,\n",
    "                      pedestrians_cropped_label,\n",
    "                      road_work_cropped_label])\n",
    "\n",
    "newImagesOHELabels = populateOHELabelsForNewImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5262d4ff-8e4b-4212-a667-97a9e7ee31b7"
    }
   },
   "outputs": [],
   "source": [
    "### Run the predictions for the new images here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "init_op = tf.global_variables_initializer()\n",
    "prediction = tf.nn.softmax(fc2)\n",
    "topPredictions=tf.nn.top_k(prediction, k=5, sorted=True, name=None)\n",
    "\n",
    "top_k_feed_dict = {x: newImages, y: newImagesOHELabels}\n",
    "\n",
    "with tf.Session() as session:\n",
    "    # Run the init operation.\n",
    "    session.run(init_op)\n",
    "    top_k_pred = session.run(topPredictions, feed_dict = top_k_feed_dict)\n",
    "    top5_pred_sftmax = top_k_pred[0]\n",
    "    top5_pred_labels = top_k_pred[1]\n",
    "\n",
    "print(newImagePaths)\n",
    "np.set_printoptions(precision=3)\n",
    "print(top5_pred_sftmax)\n",
    "print(top5_pred_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "057c050d-fd98-4734-8e23-0d30a21cabca"
    }
   },
   "source": [
    "### Question 7\n",
    "\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the dataset?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "76ab55b0-3249-4ac7-9a2d-00cc5ba78cf8"
    }
   },
   "source": [
    "**Answer:**\n",
    "Based on the above there appears to be a rather poor classification of images obtained from the web.\n",
    "The above indicates that the following was inferred (using signnames.csv)-\n",
    "- 'no_entry_cropped.jpg'-> 39:Keep left\n",
    "- 'speed_limit_60_cropped.jpg'-> 14:Stop\n",
    "- 'right_of_way_cropped.jpg'-> 23:Slippery Road\n",
    "- 'pedestrians_cropped.jpg'-> 14:Stop \n",
    "- 'road_work_cropped.jpg'-> 23:Slippery Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1b4db250-6ba9-4675-af83-cece21edf50c"
    }
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "init_op = tf.global_variables_initializer()\n",
    "prediction = tf.nn.softmax(fc2)\n",
    "topPredictions=tf.nn.top_k(prediction, k=5, sorted=True, name=None)\n",
    "\n",
    "top_k_feed_dict = {x: X_train, y: y_train}\n",
    "\n",
    "with tf.Session() as session:\n",
    "    # Run the init operation.\n",
    "    session.run(init_op)\n",
    "    top_k_pred = session.run(topPredictions, feed_dict = top_k_feed_dict)\n",
    "    top5_pred_sftmax = top_k_pred[0]\n",
    "    top5_pred_labels = top_k_pred[1]\n",
    "\n",
    "# print(newImagePaths)\n",
    "np.set_printoptions(precision=3)\n",
    "print(top5_pred_sftmax)\n",
    "print(top5_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "94390a42-b626-44c4-9583-a4aafb00d581"
    }
   },
   "source": [
    "### Question 8\n",
    "\n",
    "*Use the model's softmax probabilities to visualize the **certainty** of its predictions, [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k) could prove helpful here. Which predictions is the model certain of? Uncertain? If the model was incorrect in its initial prediction, does the correct prediction appear in the top k? (k should be 5 at most)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bc9f3899-ac90-484b-ba14-9b748bca5e1d"
    }
   },
   "source": [
    "**Answer:**\n",
    "Based on the above there appears to be a rather poor **certainty** of predictions, as the probablities are almost uniformly distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6ee1f183-aa87-4aa3-8148-bf98023c5fcb"
    }
   },
   "source": [
    "### Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1b670e50-e6f7-4b83-b80e-749b6c1fac93"
    }
   },
   "source": [
    "**Answer:**\n",
    "A web or native GUI interface has not been provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6e67c6d3-9296-4d14-953f-2d6703907a10"
    }
   },
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
